{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fastai\n",
    "import torch\n",
    "from fastai.vision.all import *\n",
    "from fastai.vision.gan import *\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7.15\n"
     ]
    }
   ],
   "source": [
    "print(fastai.__version__) # version check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = torch.load('embedding.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Custom dataset class\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mTxt2ImgDataset\u001b[39;00m(\u001b[43mDataset\u001b[49m):\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, items, embedding\u001b[38;5;241m=\u001b[39membedding, image_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m128\u001b[39m):\n\u001b[1;32m      4\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems \u001b[38;5;241m=\u001b[39m items\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Dataset' is not defined"
     ]
    }
   ],
   "source": [
    "# Custom dataset class\n",
    "class Txt2ImgDataset(Dataset):\n",
    "    def __init__(self, items, embedding=embedding, image_size=128):\n",
    "        self.items = items\n",
    "        self.embedding = embedding\n",
    "        self.image_size = image_size\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.items)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        fn = self.items[idx]\n",
    "        key = fn.name.split('.')[0] + '.txt'\n",
    "        emb = self.embedding[key].cuda()\n",
    "        img = PILImage.create(fn).resize((self.image_size, self.image_size))\n",
    "        wrong_img = self.get_wrong_image(idx)\n",
    "        noise = torch.randn(100, 1, 1).cuda()\n",
    "        emb_with_noise = torch.cat([emb, noise], 0)\n",
    "        return emb_with_noise, img, wrong_img\n",
    "\n",
    "    def get_wrong_image(self, idx):\n",
    "        wrong_idx = random.choice(range(len(self.items)))\n",
    "        while wrong_idx == idx:\n",
    "            wrong_idx = random.choice(range(len(self.items)))\n",
    "        wrong_fn = self.items[wrong_idx]\n",
    "        wrong_img = PILImage.create(wrong_fn).resize((self.image_size, self.image_size))\n",
    "        return wrong_img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Txt2ImgDataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m     dset \u001b[38;5;241m=\u001b[39m Txt2ImgDataset(items, image_size\u001b[38;5;241m=\u001b[39msize)\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m DataLoaders\u001b[38;5;241m.\u001b[39mfrom_dsets(dset, dset, bs\u001b[38;5;241m=\u001b[39mbs, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m----> 7\u001b[0m dls \u001b[38;5;241m=\u001b[39m \u001b[43mget_dls\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdata/images/\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m128\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[5], line 4\u001b[0m, in \u001b[0;36mget_dls\u001b[0;34m(path, bs, size)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_dls\u001b[39m(path, bs, size):\n\u001b[1;32m      3\u001b[0m     items \u001b[38;5;241m=\u001b[39m get_image_files(path)\n\u001b[0;32m----> 4\u001b[0m     dset \u001b[38;5;241m=\u001b[39m \u001b[43mTxt2ImgDataset\u001b[49m(items, image_size\u001b[38;5;241m=\u001b[39msize)\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m DataLoaders\u001b[38;5;241m.\u001b[39mfrom_dsets(dset, dset, bs\u001b[38;5;241m=\u001b[39mbs, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Txt2ImgDataset' is not defined"
     ]
    }
   ],
   "source": [
    "# Create DataLoaders\n",
    "def get_dls(path, bs, size):\n",
    "    items = get_image_files(path)\n",
    "    dset = Txt2ImgDataset(items, image_size=size)\n",
    "    return DataLoaders.from_dsets(dset, dset, bs=bs, shuffle=True)\n",
    "\n",
    "dls = get_dls('data/images/', bs=64, size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Txt2ImgYTransform(Transform):\n",
    "    def __init__(self, embedding=embedding, **kwargs):\n",
    "        self.embedding = embedding\n",
    "    \n",
    "    def encodes(self, fn):\n",
    "        key = fn.stem + '.txt'\n",
    "        img = PILImage.create(fn)\n",
    "        return (TensorImage(self.embedding[key]).cuda(), img)\n",
    "    \n",
    "    def decodes(self, x):\n",
    "        return PILImage(x[1].float().clamp(min=0, max=1))\n",
    "        \n",
    "    def show(self, xs, ys=None, zs=None, imgsize=4, figsize=None, **kwargs):\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Txt2ImgXTransform(Transform):\n",
    "    def __init__(self, embedding=embedding, **kwargs):\n",
    "        self.embedding = embedding\n",
    "    \n",
    "    def encodes(self, fn):\n",
    "        key = fn.stem + '.txt'\n",
    "        img = self.get_wrong_image(fn)\n",
    "        return (TensorImage(self.embedding[key]).cuda(), img)\n",
    "    \n",
    "    def get_wrong_image(self, fn):\n",
    "        cat = '_'.join(fn.name.split('_')[:-3])\n",
    "        items = fn.ls()  # List of all items in the directory\n",
    "        idx = np.random.randint(len(items))\n",
    "        \n",
    "        while items[idx].name.startswith(cat):\n",
    "            idx = np.random.randint(len(items))\n",
    "        \n",
    "        return PILImage.create(items[idx])\n",
    "\n",
    "    def decodes(self, x):\n",
    "        return PILImage(x[1].float().clamp(min=0, max=1))\n",
    "        \n",
    "    def show(self, xs, ys=None, zs=None, imgsize=4, figsize=None, **kwargs):\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dblock = DataBlock(blocks=(ImageBlock, CategoryBlock),\n",
    "                   get_items=get_image_files,\n",
    "                   splitter=FuncSplitter(lambda x: False),\n",
    "                   get_y=noop)\n",
    "\n",
    "data = dblock.dataloaders('data/images/train', bs=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item = next(iter(data.train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item[0].shape, item[0].shape, item[1].shape, item[1].shape \n",
    "\n",
    "## recheck the dataset "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_flatten(x): return x.mean(0).view(1)\n",
    "\n",
    "def AvgFlatten(): return Lambda(avg_flatten)  # now can pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def squeezer(in_dim, out_dim):\n",
    "    return nn.Sequential(\n",
    "            nn.Linear(in_dim, out_dim),\n",
    "            nn.BatchNorm1d(out_dim),\n",
    "            nn.LeakyReLU(0.2, inplace=True)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class imageGenerator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.generator = basic_generator(in_size=in_size, n_channels=3, noise_sz=228)\n",
    "        self.squeezer = squeezer(400, 128)\n",
    "    \n",
    "    def forward(self, embedding, fake_image=None):        \n",
    "        em_s = self.squeezer(embedding.view(embedding.size(0), -1))\n",
    "        em_s = em_s[:,:,None,None]\n",
    "        em_noise = torch.cat([em_s, torch.randn(em_s.size(0),100,1,1).cuda()], 1)\n",
    "        # return: (embedding, fake image)\n",
    "        return embedding, self.generator(em_noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class imageCritic(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        critic = basic_critic(in_size=in_size, n_channels=3)\n",
    "        self.body = nn.Sequential(*list(critic.children())[:-2])\n",
    "        self.head = nn.Sequential(conv2d(640, 1, 4, padding=0), \n",
    "                                  AvgFlatten())\n",
    "        self.squeezer = squeezer(400, 128)\n",
    "        \n",
    "    def forward(self, embedding, image):\n",
    "        x = self.body(image)                     # (512,4,4)\n",
    "        em_s = self.squeezer(embedding.view(embedding.size(0), -1)) \n",
    "        em_s = em_s[:,:,None,None]               # (128,1,1)\n",
    "        em_s = em_s.repeat(1,1,4,4)              # (128,4,4)\n",
    "        x = torch.cat([x, em_s], 1)              # (640,4,4)\n",
    "        x = self.head(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Loss(GANModule):    \n",
    "    def __init__(self, gan_model):\n",
    "        super().__init__()\n",
    "        self.gan_model = gan_model\n",
    "\n",
    "    def generator(self, output, *target):\n",
    "        # output: (embedding, image)\n",
    "        # target: (embedding, image)\n",
    "        fake_pred = self.gan_model.critic(*output)        \n",
    "        return fake_pred.mean()\n",
    "\n",
    "    def critic(self, real_pred, embedding, wrong_img=None):\n",
    "        # real_pred: (1,)\n",
    "        fake = self.gan_model.generator(embedding.requires_grad_(False))\n",
    "        # fake: (embedding, fake image)\n",
    "        fake[1].requires_grad_(True)\n",
    "        fake_pred = self.gan_model.critic(*fake)  \n",
    "        #wrong_pred = self.gan_model.critic(fake[0], wrong_img)\n",
    "        return real_pred.mean() - fake_pred.mean() #- wrong_pred.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Txt2ImgGANTrainer(GANTrainer):    \n",
    "    def on_backward_begin(self, last_loss, last_output, **kwargs):        \n",
    "        last_loss = last_loss.detach().cpu()\n",
    "        if self.gen_mode:\n",
    "            self.smoothenerG.add_value(last_loss)\n",
    "            self.glosses.append(self.smoothenerG.smooth)\n",
    "            # last_output: (embedding, image)\n",
    "            self.last_gen = last_output[1].detach().cpu()\n",
    "        else:\n",
    "            self.smoothenerC.add_value(last_loss)\n",
    "            self.closses.append(self.smoothenerC.smooth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = imageGenerator()\n",
    "critic = imageCritic()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
